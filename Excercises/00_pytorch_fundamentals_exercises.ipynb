{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzDBM_v4iMe7"
      },
      "source": [
        "# 00. PyTorch Fundamentals Exercises\n",
        "\n",
        "### 1. Documentation reading \n",
        "\n",
        "A big part of deep learning (and learning to code in general) is getting familiar with the documentation of a certain framework you're using. We'll be using the PyTorch documentation a lot throughout the rest of this course. So I'd recommend spending 10-minutes reading the following (it's okay if you don't get some things for now, the focus is not yet full understanding, it's awareness):\n",
        "  * The documentation on [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html#torch-tensor).\n",
        "  * The documentation on [`torch.cuda`](https://pytorch.org/docs/master/notes/cuda.html#cuda-semantics).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bGD0oD8Kizak"
      },
      "outputs": [],
      "source": [
        "# No code solution (reading)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__iXqqz-ioUJ"
      },
      "source": [
        "### 2. Create a random tensor with shape `(7, 7)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6pUq9Dc8i2L7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([7, 7])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import torch\n",
        "import torch\n",
        "\n",
        "# Create random tensor\n",
        "tensor = torch.rand((7,7))\n",
        "tensor.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-XxvRLfiqkR"
      },
      "source": [
        "### 3. Perform a matrix multiplication on the tensor from 2 with another random tensor with shape `(1, 7)` (hint: you may have to transpose the second tensor)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NcLqR0Sbi_vT"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.7494],\n",
              "        [1.2494],\n",
              "        [1.4017],\n",
              "        [1.3572],\n",
              "        [1.3336],\n",
              "        [1.1400],\n",
              "        [1.6105]])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create another random tensor\n",
        "tensor_2 = torch.rand((1 , 7))\n",
        "# Perform matrix multiplication \n",
        "torch.mm(tensor , tensor_2.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiutdKUFiryU"
      },
      "source": [
        "### 4. Set the random seed to `0` and do 2 & 3 over again.\n",
        "\n",
        "The output should be:\n",
        "```\n",
        "(tensor([[1.8542],\n",
        "         [1.9611],\n",
        "         [2.2884],\n",
        "         [3.0481],\n",
        "         [1.7067],\n",
        "         [2.5290],\n",
        "         [1.7989]]), torch.Size([7, 1]))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "D-lOWI_1jRMm"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[18], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m tenosr_a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m7\u001b[39m))\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Matrix multiply tensors\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     12\u001b[0m result , result\u001b[38;5;241m.\u001b[39mshape\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)"
          ]
        }
      ],
      "source": [
        "# Set manual seed\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "\n",
        "# Create two random tensors\n",
        "tensor_b = torch.rand((7,7))\n",
        "tenosr_a = torch.rand((1,7))\n",
        "\n",
        "# Matrix multiply tensors\n",
        "result = torch.mm(tensor , tensor_2.T) \n",
        "result , result.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezY6ks9Cis37"
      },
      "source": [
        "### 5. Speaking of random seeds, we saw how to set it with `torch.manual_seed()` but is there a GPU equivalent? (hint: you'll need to look into the documentation for `torch.cuda` for this one)\n",
        "  * If there is, set the GPU random seed to `1234`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_LKWcfSTjp00"
      },
      "outputs": [],
      "source": [
        "# Set random seed on the GPU\n",
        "torch.cuda.manual_seed(1234)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir9qSaj6it4n"
      },
      "source": [
        "\n",
        "### 6. Create two random tensors of shape `(2, 3)` and send them both to the GPU (you'll need access to a GPU for this). Set `torch.manual_seed(1234)` when creating the tensors (this doesn't have to be the GPU random seed). The output should be something like:\n",
        "\n",
        "```\n",
        "Device: cuda\n",
        "(tensor([[0.0290, 0.4019, 0.2598],\n",
        "         [0.3666, 0.0583, 0.7006]], device='cuda:0'),\n",
        " tensor([[0.0518, 0.4681, 0.6738],\n",
        "         [0.3315, 0.7837, 0.5631]], device='cuda:0'))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "azXExiFZj5nm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device:  cuda\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(tensor([[0.5932, 0.1123, 0.1535],\n",
              "         [0.2417, 0.7262, 0.7011]], device='cuda:0'),\n",
              " tensor([[0.2038, 0.6511, 0.7745],\n",
              "         [0.4369, 0.5191, 0.6159]], device='cuda:0'))"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set random seed\n",
        "seed = 1234\n",
        "\n",
        "# Check for access to GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# Create two random tensors on GPU\n",
        "tensor_1 = torch.rand((2,3)).to(device)\n",
        "tensor_2 = torch.rand((2,3)).to(device)\n",
        "print('Device: ' , device)\n",
        "tensor_1 , tensor_2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TlAxeiSiu1y"
      },
      "source": [
        "\n",
        "### 7. Perform a matrix multiplication on the tensors you created in 6 (again, you may have to adjust the shapes of one of the tensors).\n",
        "\n",
        "The output should look like:\n",
        "```\n",
        "(tensor([[0.3647, 0.4709],\n",
        "         [0.5184, 0.5617]], device='cuda:0'), torch.Size([2, 2]))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "fAeG7ox0lHEO"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.3129, 0.4120],\n",
              "        [1.0651, 0.9143]], device='cuda:0')"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Perform matmul on tensor_A and tensor_B\n",
        "result = torch.mm(tensor_1 , tensor_2.T)\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7qfa5CSivwg"
      },
      "source": [
        "### 8. Find the maximum and minimum values of the output of 7."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Fu8_3mZpllOd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.0651, device='cuda:0')\n",
            "tensor(0.3129, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# Find max\n",
        "print(torch.max(result))\n",
        "# Find min\n",
        "print(torch.min(result))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrTj5FgNiw47"
      },
      "source": [
        "### 9. Find the maximum and minimum index values of the output of 7."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CCEKt4K2lsfQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# Find arg max\n",
        "print(torch.argmax(result))\n",
        "\n",
        "# Find arg min\n",
        "print(torch.argmin(result))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmeybz4uixy7"
      },
      "source": [
        "\n",
        "### 10. Make a random tensor with shape `(1, 1, 1, 10)` and then create a new tensor with all the `1` dimensions removed to be left with a tensor of shape `(10)`. Set the seed to `7` when you create it and print out the first tensor and it's shape as well as the second tensor and it's shape.\n",
        "\n",
        "The output should look like:\n",
        "\n",
        "```\n",
        "tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,\n",
        "           0.3653, 0.8513]]]]) torch.Size([1, 1, 1, 10])\n",
        "tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n",
        "        0.8513]) torch.Size([10])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "TQ9zbRzVl1jV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,\n",
            "           0.3653, 0.8513]]]]) torch.Size([1, 1, 1, 10])\n",
            "tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n",
            "        0.8513]) torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "# Set seed\n",
        "torch.manual_seed(7)\n",
        "\n",
        "\n",
        "# Create random tensor\n",
        "random_tensor = torch.rand((1,1,1,10))\n",
        "\n",
        "# Remove single dimensions\n",
        "modified_tensor = random_tensor.squeeze()\n",
        "\n",
        "# Print out tensors and their shapes\n",
        "print(random_tensor , random_tensor.shape)\n",
        "print(modified_tensor , modified_tensor.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('active.all.allocated', 268),\n",
              "             ('active.all.current', 11),\n",
              "             ('active.all.freed', 257),\n",
              "             ('active.all.peak', 17),\n",
              "             ('active.large_pool.allocated', 1),\n",
              "             ('active.large_pool.current', 1),\n",
              "             ('active.large_pool.freed', 0),\n",
              "             ('active.large_pool.peak', 1),\n",
              "             ('active.small_pool.allocated', 267),\n",
              "             ('active.small_pool.current', 10),\n",
              "             ('active.small_pool.freed', 257),\n",
              "             ('active.small_pool.peak', 16),\n",
              "             ('active_bytes.all.allocated', 8662528),\n",
              "             ('active_bytes.all.current', 8524800),\n",
              "             ('active_bytes.all.freed', 137728),\n",
              "             ('active_bytes.all.peak', 8527872),\n",
              "             ('active_bytes.large_pool.allocated', 8519680),\n",
              "             ('active_bytes.large_pool.current', 8519680),\n",
              "             ('active_bytes.large_pool.freed', 0),\n",
              "             ('active_bytes.large_pool.peak', 8519680),\n",
              "             ('active_bytes.small_pool.allocated', 142848),\n",
              "             ('active_bytes.small_pool.current', 5120),\n",
              "             ('active_bytes.small_pool.freed', 137728),\n",
              "             ('active_bytes.small_pool.peak', 8192),\n",
              "             ('allocated_bytes.all.allocated', 8662528),\n",
              "             ('allocated_bytes.all.current', 8524800),\n",
              "             ('allocated_bytes.all.freed', 137728),\n",
              "             ('allocated_bytes.all.peak', 8527872),\n",
              "             ('allocated_bytes.large_pool.allocated', 8519680),\n",
              "             ('allocated_bytes.large_pool.current', 8519680),\n",
              "             ('allocated_bytes.large_pool.freed', 0),\n",
              "             ('allocated_bytes.large_pool.peak', 8519680),\n",
              "             ('allocated_bytes.small_pool.allocated', 142848),\n",
              "             ('allocated_bytes.small_pool.current', 5120),\n",
              "             ('allocated_bytes.small_pool.freed', 137728),\n",
              "             ('allocated_bytes.small_pool.peak', 8192),\n",
              "             ('allocation.all.allocated', 268),\n",
              "             ('allocation.all.current', 11),\n",
              "             ('allocation.all.freed', 257),\n",
              "             ('allocation.all.peak', 17),\n",
              "             ('allocation.large_pool.allocated', 1),\n",
              "             ('allocation.large_pool.current', 1),\n",
              "             ('allocation.large_pool.freed', 0),\n",
              "             ('allocation.large_pool.peak', 1),\n",
              "             ('allocation.small_pool.allocated', 267),\n",
              "             ('allocation.small_pool.current', 10),\n",
              "             ('allocation.small_pool.freed', 257),\n",
              "             ('allocation.small_pool.peak', 16),\n",
              "             ('inactive_split.all.allocated', 110),\n",
              "             ('inactive_split.all.current', 2),\n",
              "             ('inactive_split.all.freed', 108),\n",
              "             ('inactive_split.all.peak', 4),\n",
              "             ('inactive_split.large_pool.allocated', 1),\n",
              "             ('inactive_split.large_pool.current', 1),\n",
              "             ('inactive_split.large_pool.freed', 0),\n",
              "             ('inactive_split.large_pool.peak', 1),\n",
              "             ('inactive_split.small_pool.allocated', 109),\n",
              "             ('inactive_split.small_pool.current', 1),\n",
              "             ('inactive_split.small_pool.freed', 108),\n",
              "             ('inactive_split.small_pool.peak', 3),\n",
              "             ('inactive_split_bytes.all.allocated', 14686208),\n",
              "             ('inactive_split_bytes.all.current', 14543872),\n",
              "             ('inactive_split_bytes.all.freed', 142336),\n",
              "             ('inactive_split_bytes.all.peak', 14547456),\n",
              "             ('inactive_split_bytes.large_pool.allocated', 12451840),\n",
              "             ('inactive_split_bytes.large_pool.current', 12451840),\n",
              "             ('inactive_split_bytes.large_pool.freed', 0),\n",
              "             ('inactive_split_bytes.large_pool.peak', 12451840),\n",
              "             ('inactive_split_bytes.small_pool.allocated', 2234368),\n",
              "             ('inactive_split_bytes.small_pool.current', 2092032),\n",
              "             ('inactive_split_bytes.small_pool.freed', 142336),\n",
              "             ('inactive_split_bytes.small_pool.peak', 2096640),\n",
              "             ('max_split_size', -1),\n",
              "             ('num_alloc_retries', 0),\n",
              "             ('num_ooms', 0),\n",
              "             ('oversize_allocations.allocated', 0),\n",
              "             ('oversize_allocations.current', 0),\n",
              "             ('oversize_allocations.freed', 0),\n",
              "             ('oversize_allocations.peak', 0),\n",
              "             ('oversize_segments.allocated', 0),\n",
              "             ('oversize_segments.current', 0),\n",
              "             ('oversize_segments.freed', 0),\n",
              "             ('oversize_segments.peak', 0),\n",
              "             ('requested_bytes.all.allocated', 8531235),\n",
              "             ('requested_bytes.all.current', 8519876),\n",
              "             ('requested_bytes.all.freed', 11359),\n",
              "             ('requested_bytes.all.peak', 8520686),\n",
              "             ('requested_bytes.large_pool.allocated', 8519680),\n",
              "             ('requested_bytes.large_pool.current', 8519680),\n",
              "             ('requested_bytes.large_pool.freed', 0),\n",
              "             ('requested_bytes.large_pool.peak', 8519680),\n",
              "             ('requested_bytes.small_pool.allocated', 11555),\n",
              "             ('requested_bytes.small_pool.current', 196),\n",
              "             ('requested_bytes.small_pool.freed', 11359),\n",
              "             ('requested_bytes.small_pool.peak', 1006),\n",
              "             ('reserved_bytes.all.allocated', 23068672),\n",
              "             ('reserved_bytes.all.current', 23068672),\n",
              "             ('reserved_bytes.all.freed', 0),\n",
              "             ('reserved_bytes.all.peak', 23068672),\n",
              "             ('reserved_bytes.large_pool.allocated', 20971520),\n",
              "             ('reserved_bytes.large_pool.current', 20971520),\n",
              "             ('reserved_bytes.large_pool.freed', 0),\n",
              "             ('reserved_bytes.large_pool.peak', 20971520),\n",
              "             ('reserved_bytes.small_pool.allocated', 2097152),\n",
              "             ('reserved_bytes.small_pool.current', 2097152),\n",
              "             ('reserved_bytes.small_pool.freed', 0),\n",
              "             ('reserved_bytes.small_pool.peak', 2097152),\n",
              "             ('segment.all.allocated', 2),\n",
              "             ('segment.all.current', 2),\n",
              "             ('segment.all.freed', 0),\n",
              "             ('segment.all.peak', 2),\n",
              "             ('segment.large_pool.allocated', 1),\n",
              "             ('segment.large_pool.current', 1),\n",
              "             ('segment.large_pool.freed', 0),\n",
              "             ('segment.large_pool.peak', 1),\n",
              "             ('segment.small_pool.allocated', 1),\n",
              "             ('segment.small_pool.current', 1),\n",
              "             ('segment.small_pool.freed', 0),\n",
              "             ('segment.small_pool.peak', 1)])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.memory_stats()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "00_pytorch_fundamentals_exercises.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
